{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 3: Collaborative Filtering Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table of content\n",
    "#### 1) Loading the files\n",
    "#### 2) User-based Collaborative Filtering :\n",
    "#####     Pivot \n",
    "#####     converting to matrix \n",
    "#####     calculating the similarity\n",
    "#####     calculating rmse "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change to the location of data files\n",
    "dbfs_dir = 's3://archanamaroldsde.bucket/'\n",
    "test = dbfs_dir + '/TestingRatings.txt'\n",
    "train = dbfs_dir + '/TrainingRatings.txt'\n",
    "names= dbfs_dir + '/movie_titles.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://archanamaroldsde.bucket//TestingRatings.txt'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MovieID,UserID,Rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import regexp_extract\n",
    "from pyspark.sql.types import *\n",
    "import pandas\n",
    "tests=sqlContext.read.text(test)\n",
    "trains=sqlContext.read.text(train)\n",
    "movie_names=sqlContext.read.text(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as f\n",
    "test_data = tests.select(f.split(tests.value,\",\")).rdd.flatMap(lambda x: x).toDF(schema=[\"movieID\",\"userID\", \"rating\"])\n",
    "train_data = trains.select(f.split(trains.value,\",\")).rdd.flatMap(lambda x: x).toDF(schema=[\"movieID\",\"userID\", \"rating\"])\n",
    "movie_name = movie_names.select(f.split(movie_names.value,\",\")).rdd.flatMap(lambda x: x).toDF(schema=[\"movieID\",\"year\", \"title\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting types\n",
    "test_data = test_data.withColumn(\"movieID\",test_data[\"movieID\"].cast(IntegerType()))\n",
    "test_data = test_data.withColumn(\"userID\",test_data[\"userID\"].cast(IntegerType()))\n",
    "test_data = test_data.withColumn(\"rating\",test_data[\"rating\"].cast(FloatType()))\n",
    "\n",
    "train_data = train_data.withColumn(\"movieID\",train_data[\"movieID\"].cast(IntegerType()))\n",
    "train_data = train_data.withColumn(\"userID\",train_data[\"userID\"].cast(IntegerType()))\n",
    "train_data = train_data.withColumn(\"rating\",train_data[\"rating\"].cast(FloatType()))\n",
    "\n",
    "movie_name = movie_name.withColumn(\"movieID\",movie_name[\"movieID\"].cast(IntegerType()))\n",
    "movie_name = movie_name.withColumn(\"year\",movie_name[\"year\"].cast(IntegerType()))\n",
    "movie_name = movie_name.withColumn(\"title\",movie_name[\"title\"].cast(StringType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+------+\n",
      "|movieID| userID|rating|\n",
      "+-------+-------+------+\n",
      "|      8| 573364|   1.0|\n",
      "|      8|2149668|   3.0|\n",
      "|      8|1089184|   3.0|\n",
      "+-------+-------+------+\n",
      "only showing top 3 rows\n",
      "\n",
      "None\n",
      "+-------+-------+------+\n",
      "|movieID| userID|rating|\n",
      "+-------+-------+------+\n",
      "|      8|1744889|   1.0|\n",
      "|      8|1395430|   2.0|\n",
      "|      8|1205593|   4.0|\n",
      "+-------+-------+------+\n",
      "only showing top 3 rows\n",
      "\n",
      "None\n",
      "+-------+----+--------------------+\n",
      "|movieID|year|               title|\n",
      "+-------+----+--------------------+\n",
      "|      1|2003|     Dinosaur Planet|\n",
      "|      2|2004|Isle of Man TT 20...|\n",
      "|      3|1997|           Character|\n",
      "+-------+----+--------------------+\n",
      "only showing top 3 rows\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(test_data.show(3))\n",
    "print(train_data.show(3))\n",
    "print(movie_name.show(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.cache()\n",
    "train_data.cache()\n",
    "assert test_data.is_cached\n",
    "assert train_data.is_cached"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 3255352 rows in the train datasets\n",
      "There are 100478 rows in the test datasets\n"
     ]
    }
   ],
   "source": [
    "train_data_count = train_data.count()\n",
    "test_data_count = test_data.count()\n",
    "print('There are %s rows in the train datasets' % (train_data_count))\n",
    "print('There are %s rows in the test datasets' % (test_data_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User-based Collaborative Filtering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import math\n",
    "import pandas as pd\n",
    "from math import sqrt\n",
    "from sklearn.metrics.pairwise import pairwise_distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pivoting the data for user-user filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_matrix=test_data.pivot(index='userID', columns='movieID', values='rating')\n",
    "test_data_matrix1=test_data_matrix.fillna(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting the data into a sparse matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_matrix2=test_data_matrix1.values\n",
    "test_data_matrix2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### pivoting and converting to matrix for train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_matrix=train_data.pivot(index='userID', columns='movieID', values='rating')\n",
    "train_data_matrix1=train_data_matrix.fillna(0)\n",
    "train_data_matrix2=train_data_matrix1.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.,  4.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  4.,  0., ...,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_matrix2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### calculating the similiarity using correlation metric \n",
    "#### User-similarity and Item-similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_similarity1=pairwise_distances(train_data_matrix2, metric='correlation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_similarity1 = pairwise_distances(train_data_matrix2.T, metric='correlation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(rating, similarity, type1):\n",
    "    if type1=='user':\n",
    "        mean_user_rating=rating.mean(axis=1)\n",
    "        #print('rating',rating.head(2))\n",
    "        #print(mean_user_rating.shape)\n",
    "        rating_diff=(rating-mean_user_rating[:, np.newaxis])\n",
    "        #print(rating_diff.shape)\n",
    "        pred=mean_user_rating[:,np.newaxis] + similarity.dot(rating_diff)/np.array([np.abs(similarity).sum(axis=1)]).T\n",
    "    elif type1 == 'item':\n",
    "        pred = rating.dot(similarity) / np.array([np.abs(similarity).sum(axis=1)])\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_pred=predict(train_data_matrix2, user_similarity1, type1='user')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_pred = predict(train_data_matrix2, item_similarity1, type1='item')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.30873919  1.55873792  0.01425974 ...,  0.01367812  0.13005357\n",
      "   0.03352018]\n",
      " [ 0.26556504  1.4820479  -0.04185526 ..., -0.04224655  0.07490007\n",
      "  -0.02278229]\n",
      " [ 0.24052187  1.55577568 -0.05571908 ..., -0.05610593  0.0554129\n",
      "  -0.03475516]\n",
      " ..., \n",
      " [ 0.2393442   1.59472163 -0.0460224  ..., -0.04676259  0.06388082\n",
      "  -0.02584937]\n",
      " [ 0.26144077  1.49979728 -0.03859018 ..., -0.03912957  0.07507935\n",
      "  -0.0195167 ]\n",
      " [ 0.26647638  1.44693597 -0.03846407 ..., -0.03871254  0.07485795\n",
      "  -0.01942068]]\n"
     ]
    }
   ],
   "source": [
    "print(user_pred)\n",
    "#print(item_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RMSE and MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(prediction, ground_truth):\n",
    "    prediction = prediction[ground_truth.nonzero()].flatten()\n",
    "    ground_truth = ground_truth[ground_truth.nonzero()].flatten()\n",
    "    return sqrt(mean_squared_error(prediction, ground_truth)), mean_squared_error(prediction, ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User-based MSE :  12.0061213538\n",
      "User-based RMSE :  3.4649850438084355\n"
     ]
    }
   ],
   "source": [
    "rmse,mse=rmse(user_pred, test_data_matrix2)\n",
    "print('User-based MSE : ' ,mse)\n",
    "print('User-based RMSE : ' ,rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item-based MSE :  11.8230753587\n",
      "Item-based RMSE :  3.438469915343497\n"
     ]
    }
   ],
   "source": [
    "rmse1,mse1=rmse(item_pred, test_data_matrix2)\n",
    "print('Item-based MSE : ' ,mse1)\n",
    "print('Item-based RMSE : ',rmse1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
