{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2: Analyzing the Netflix Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Content\n",
    "\n",
    "#### a) how many distinct items and how many distinct users are there in the test set?\n",
    "#### b) overlappingitems and overlappingusers\n",
    "#### c) Best approach to implement the collaborative filtering \n",
    "#### d) Applying Correlation Coefficient and rerunning the code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading the files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change to the location of data files\n",
    "dbfs_dir = 's3://archanamaroldsde.bucket/'\n",
    "test = dbfs_dir + '/TestingRatings.txt'\n",
    "train = dbfs_dir + '/TrainingRatings.txt'\n",
    "names= dbfs_dir + '/movie_titles.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://archanamaroldsde.bucket//TestingRatings.txt'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MovieID,UserID,Rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import regexp_extract\n",
    "from pyspark.sql.types import *\n",
    "import pandas\n",
    "tests=sqlContext.read.text(test)\n",
    "trains=sqlContext.read.text(train)\n",
    "movie_names=sqlContext.read.text(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as f\n",
    "test_data = tests.select(f.split(tests.value,\",\")).rdd.flatMap(lambda x: x).toDF(schema=[\"movieID\",\"userID\", \"rating\"])\n",
    "train_data = trains.select(f.split(trains.value,\",\")).rdd.flatMap(lambda x: x).toDF(schema=[\"movieID\",\"userID\", \"rating\"])\n",
    "movie_name = movie_names.select(f.split(movie_names.value,\",\")).rdd.flatMap(lambda x: x).toDF(schema=[\"movieID\",\"year\", \"title\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting types\n",
    "test_data = test_data.withColumn(\"movieID\",test_data[\"movieID\"].cast(IntegerType()))\n",
    "test_data = test_data.withColumn(\"userID\",test_data[\"userID\"].cast(IntegerType()))\n",
    "test_data = test_data.withColumn(\"rating\",test_data[\"rating\"].cast(FloatType()))\n",
    "\n",
    "train_data = train_data.withColumn(\"movieID\",train_data[\"movieID\"].cast(IntegerType()))\n",
    "train_data = train_data.withColumn(\"userID\",train_data[\"userID\"].cast(IntegerType()))\n",
    "train_data = train_data.withColumn(\"rating\",train_data[\"rating\"].cast(FloatType()))\n",
    "\n",
    "movie_name = movie_name.withColumn(\"movieID\",movie_name[\"movieID\"].cast(IntegerType()))\n",
    "movie_name = movie_name.withColumn(\"year\",movie_name[\"year\"].cast(IntegerType()))\n",
    "movie_name = movie_name.withColumn(\"title\",movie_name[\"title\"].cast(StringType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+------+\n",
      "|movieID| userID|rating|\n",
      "+-------+-------+------+\n",
      "|      8| 573364|   1.0|\n",
      "|      8|2149668|   3.0|\n",
      "|      8|1089184|   3.0|\n",
      "+-------+-------+------+\n",
      "only showing top 3 rows\n",
      "\n",
      "None\n",
      "+-------+-------+------+\n",
      "|movieID| userID|rating|\n",
      "+-------+-------+------+\n",
      "|      8|1744889|   1.0|\n",
      "|      8|1395430|   2.0|\n",
      "|      8|1205593|   4.0|\n",
      "+-------+-------+------+\n",
      "only showing top 3 rows\n",
      "\n",
      "None\n",
      "+-------+----+--------------------+\n",
      "|movieID|year|               title|\n",
      "+-------+----+--------------------+\n",
      "|      1|2003|     Dinosaur Planet|\n",
      "|      2|2004|Isle of Man TT 20...|\n",
      "|      3|1997|           Character|\n",
      "+-------+----+--------------------+\n",
      "only showing top 3 rows\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(test_data.show(3))\n",
    "print(train_data.show(3))\n",
    "print(movie_name.show(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.cache()\n",
    "train_data.cache()\n",
    "assert test_data.is_cached\n",
    "assert train_data.is_cached"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 3255352 rows in the train datasets\n",
      "There are 100478 rows in the test datasets\n"
     ]
    }
   ],
   "source": [
    "train_data_count = train_data.count()\n",
    "test_data_count = test_data.count()\n",
    "print('There are %s rows in the train datasets' % (train_data_count))\n",
    "print('There are %s rows in the test datasets' % (test_data_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# a) how many distinct items and how many distinct users are there in the test set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distinct movies:\n",
      "1701\n"
     ]
    }
   ],
   "source": [
    "d1=test_data.select('movieID').distinct().count()\n",
    "print(\"Distinct movies:\")\n",
    "print(d1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distinct users\n",
      "27555\n"
     ]
    }
   ],
   "source": [
    "d2=test_data.select('userID').distinct().count()\n",
    "print(\"Distinct users\")\n",
    "print(d2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# b) overlappingitems and overlappingusers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "part B has the analysis part. The prediction part is covered in part D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b 1) user similarities are measured by overlappingitems\n",
    "### user 199435"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movies of userid 199435 in test set\n",
      "+-------+------+------+\n",
      "|movieID|userID|rating|\n",
      "+-------+------+------+\n",
      "|    443|199435|   3.0|\n",
      "|   4852|199435|   2.0|\n",
      "|   7145|199435|   3.0|\n",
      "|   8596|199435|   5.0|\n",
      "|  10082|199435|   2.0|\n",
      "+-------+------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# lets pick an user 199435\n",
    "movies_user=test_data.filter(\"userID  == 199435\")\n",
    "print(\"movies of userid 199435 in test set\")\n",
    "movies_user.show(5)\n",
    "#lets collect them in a list\n",
    "list1 = movies_user.select('movieID')\n",
    "array = [int(row.movieID) for row in list1.collect()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of movies user watched in the train set:\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "print(\"No of movies user watched in the train set:\")\n",
    "print(movies_user.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of users in the train set, who has watched the same movie as 199435 watched are: 92691\n",
      "+-------+-------+------+\n",
      "|movieID| userID|rating|\n",
      "+-------+-------+------+\n",
      "|    443| 364518|   3.0|\n",
      "|    443| 716091|   4.0|\n",
      "|    443|1601783|   4.0|\n",
      "|    443| 306466|   3.0|\n",
      "|    443| 160977|   5.0|\n",
      "+-------+-------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#now lets get all the users in the train set, who has watched the same movie as 199435 watched\n",
    "count=train_data[train_data['movieID'].isin(array)].count()\n",
    "print(\"The number of users in the train set, who has watched the same movie as 199435 watched are:\", count)\n",
    "users=train_data[train_data['movieID'].isin(array)]\n",
    "users.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "x=users.groupBy(\"userID\").agg(F.count('movieID').alias(\"count1\"))\n",
    "y=x.orderBy(x.count1.desc()).limit(10)\n",
    "#storing in an array\n",
    "list2 = y.select('userID')\n",
    "array2 = [int(row.userID) for row in list2.collect()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### average overlap of items rated by the users in the training set for users in the test set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average over all the items of that users similar to the userid 199435 \n",
      "+-------+----------+\n",
      "|movieID|prediction|\n",
      "+-------+----------+\n",
      "|  10082|       2.8|\n",
      "|   4852|       3.4|\n",
      "|   8596|       4.5|\n",
      "|  14144|       3.9|\n",
      "|    443|       3.4|\n",
      "|  12778|       3.6|\n",
      "|   7145|       4.2|\n",
      "|  14712|       3.6|\n",
      "+-------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "users2=users[users['userID'].isin(array2)]\n",
    "print(\"Average over all the items of that users similar to the userid 199435 \")\n",
    "users3= users2.groupBy(\"movieID\").agg(F.mean('rating'). alias('prediction'))\n",
    "users3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+------+\n",
      "|movieID|userID|rating|\n",
      "+-------+------+------+\n",
      "|    443|199435|   3.0|\n",
      "|   4852|199435|   2.0|\n",
      "|   7145|199435|   3.0|\n",
      "|   8596|199435|   5.0|\n",
      "|  10082|199435|   2.0|\n",
      "|  12778|199435|   2.0|\n",
      "|  14144|199435|   3.0|\n",
      "|  14712|199435|   3.0|\n",
      "+-------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#actual values\n",
    "movies_user.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+------+----------+\n",
      "|movieID|userID|rating|prediction|\n",
      "+-------+------+------+----------+\n",
      "|  10082|199435|   2.0|       2.8|\n",
      "|   4852|199435|   2.0|       3.4|\n",
      "|   8596|199435|   5.0|       4.5|\n",
      "|  14144|199435|   3.0|       3.9|\n",
      "|    443|199435|   3.0|       3.4|\n",
      "|  12778|199435|   2.0|       3.6|\n",
      "|   7145|199435|   3.0|       4.2|\n",
      "|  14712|199435|   3.0|       3.6|\n",
      "+-------+------+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final1 = movies_user.join(users3, on=['movieID' ], how='inner')\n",
    "final1.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " the predicted and actual are close values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tried for few more userids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average over all the items of that users similar to the userid 573364 \n",
      "+-------+------+------+----------+\n",
      "|movieID|userID|rating|prediction|\n",
      "+-------+------+------+----------+\n",
      "|      8|573364|   1.0|       2.9|\n",
      "|   2913|573364|   4.0|       3.9|\n",
      "|    398|573364|   3.0|       3.4|\n",
      "|   2640|573364|   3.0|       4.1|\n",
      "+-------+------+------+----------+\n",
      "\n",
      "Average over all the items of that users similar to the userid 2149668 \n",
      "+-------+-------+------+----------+\n",
      "|movieID| userID|rating|prediction|\n",
      "+-------+-------+------+----------+\n",
      "|      8|2149668|   3.0|       2.7|\n",
      "|   1046|2149668|   3.0|       3.2|\n",
      "|   6190|2149668|   3.0|       3.3|\n",
      "|  12778|2149668|   3.0|       4.2|\n",
      "|   8699|2149668|   4.0|       3.3|\n",
      "|   8039|2149668|   4.0|       3.3|\n",
      "+-------+-------+------+----------+\n",
      "\n",
      "Average over all the items of that users similar to the userid 1089184 \n",
      "+-------+-------+------+----------+\n",
      "|movieID| userID|rating|prediction|\n",
      "+-------+-------+------+----------+\n",
      "|      8|1089184|   3.0|       3.0|\n",
      "|   7544|1089184|   1.0|       3.2|\n",
      "|   1884|1089184|   2.0|       3.4|\n",
      "|  10734|1089184|   1.0|       4.1|\n",
      "+-------+-------+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# lets pick an user 199435\n",
    "#movies_user=test_data.filter(\"userID  == 573364\")\n",
    "#movies_user=test_data.filter(\"userID  == 2149668\")\n",
    "movies_user=test_data.filter(\"userID  == 1089184\")\n",
    "\n",
    "#print(\"movies of userid 199435 in test set\")\n",
    "#movies_user.show(5)\n",
    "#lets collect them in a list\n",
    "list1 = movies_user.select('movieID')\n",
    "array = [int(row.movieID) for row in list1.collect()]\n",
    "\n",
    "count=train_data[train_data['movieID'].isin(array)].count()\n",
    "#print(\"The number of users in the train set, who has watched the same movie as 199435 watched are:\", count)\n",
    "users=train_data[train_data['movieID'].isin(array)]\n",
    "#users.show(5)\n",
    "\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "#lets take only those users who has watched more than 200 movies as the main user movies are 260\n",
    "x=users.groupBy(\"userID\").agg(F.count('movieID').alias(\"count1\"))\n",
    "y=x.orderBy(x.count1.desc()).limit(10)\n",
    "#storing in an array\n",
    "list2 = y.select('userID')\n",
    "array2 = [int(row.userID) for row in list2.collect()]\n",
    "\n",
    "\n",
    "\n",
    "from pyspark.sql import functions as F\n",
    "users2=users[users['userID'].isin(array2)]\n",
    "\n",
    "users3= users2.groupBy(\"movieID\").agg(F.mean('rating'). alias('prediction'))\n",
    "#users3.show()\n",
    "\n",
    "final3 = movies_user.join(users3, on=['movieID' ], how='inner')\n",
    "\n",
    "print(\"Average over all the items of that users similar to the userid 573364 \")\n",
    "final1.show()\n",
    "print(\"Average over all the items of that users similar to the userid 2149668 \")\n",
    "final2.show()\n",
    "print(\"Average over all the items of that users similar to the userid 1089184 \")\n",
    "final3.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b 2) item similarities are measured by overlappingusers\n",
    "### average overlap of users that rated items in the training set for items appearing in the test set\n",
    "### lets consider movieid 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "users of movieid 28 in train set\n",
      "+-------+-------+------+\n",
      "|movieID| userID|rating|\n",
      "+-------+-------+------+\n",
      "|     28| 991725|   3.0|\n",
      "|     28|2628220|   4.0|\n",
      "|     28| 946314|   4.0|\n",
      "|     28|2370740|   4.0|\n",
      "|     28|1100912|   4.0|\n",
      "+-------+-------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# lets pick a movie\n",
    "users_movie=test_data.filter(\"movieID  == 28\")\n",
    "print(\"users of movieid 28 in train set\")\n",
    "users_movie.show(5)\n",
    "#lets collect them in a list\n",
    "list3 = users_movie.select('userID')\n",
    "array3 = [int(row.userID) for row in list3.collect()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of users who watched this movie in the train set:\n",
      "96\n"
     ]
    }
   ],
   "source": [
    "print(\"No of users who watched this movie in the train set:\")\n",
    "print(users_movie.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of movies in the train set, that are been watched by the same users who watched movie 28: 44773\n",
      "+-------+-------+------+\n",
      "|movieID| userID|rating|\n",
      "+-------+-------+------+\n",
      "|      8| 991725|   4.0|\n",
      "|      8| 603277|   1.0|\n",
      "|      8|1645535|   3.0|\n",
      "|      8|2487958|   5.0|\n",
      "|      8| 303821|   3.0|\n",
      "+-------+-------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#now lets get all the movies in the train set, that are watched by the same users who watched movie 28\n",
    "count=train_data[train_data['userID'].isin(array3)].count()\n",
    "print(\"The number of movies in the train set, that are been watched by the same users who watched movie 28:\", count)\n",
    "movies=train_data[train_data['userID'].isin(array3)]\n",
    "movies.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+\n",
      "|movieID|count1|\n",
      "+-------+------+\n",
      "|   6287|   330|\n",
      "|   6971|   326|\n",
      "|  10947|   314|\n",
      "|  15582|   313|\n",
      "+-------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "x=movies.groupBy(\"movieID\").agg(F.count('userID').alias(\"count1\"))\n",
    "y=x.orderBy(x.count1.desc()).limit(4)\n",
    "y.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average over all the users of whose movies similar to the movie 28 \n",
      "+-------+---------+\n",
      "| userID|predicted|\n",
      "+-------+---------+\n",
      "|1518104|      5.0|\n",
      "| 830282|      5.0|\n",
      "| 393730|      5.0|\n",
      "|1563429|      5.0|\n",
      "|1290593|      5.0|\n",
      "|1249490|      5.0|\n",
      "| 591184|      5.0|\n",
      "|2229986|      5.0|\n",
      "|2101762|      5.0|\n",
      "| 336578|      5.0|\n",
      "|1704223|      5.0|\n",
      "|  75384|      5.0|\n",
      "|2252217|      5.0|\n",
      "| 875719|      5.0|\n",
      "| 282447|      5.0|\n",
      "| 452001|      5.0|\n",
      "|2179596|      5.0|\n",
      "| 459468|      5.0|\n",
      "|1745577|      5.0|\n",
      "|1646639|      5.0|\n",
      "| 633303|      5.0|\n",
      "|2057611|      5.0|\n",
      "| 714802|      5.0|\n",
      "|2554750|      5.0|\n",
      "|2375058|      5.0|\n",
      "|  62655|      5.0|\n",
      "|1787038|      5.0|\n",
      "| 498716|     4.75|\n",
      "|1242044|     4.75|\n",
      "|2015182|     4.75|\n",
      "+-------+---------+\n",
      "only showing top 30 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#storing in an array\n",
    "list2 = y.select('movieID')\n",
    "array2 = [int(row.movieID) for row in list2.collect()]\n",
    "\n",
    "from pyspark.sql import functions as F\n",
    "movies2=movies[movies['movieID'].isin(array2)]\n",
    "print(\"Average over all the users of whose movies similar to the movie 28 \")\n",
    "movies3=movies2.groupBy(\"userID\").agg(F.mean('rating').alias('predicted'))\n",
    "movies3=movies3.orderBy(movies3.predicted.desc())\n",
    "movies3.show(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+------+---------+\n",
      "| userID|movieID|rating|predicted|\n",
      "+-------+-------+------+---------+\n",
      "| 459468|     28|   5.0|      5.0|\n",
      "|  62655|     28|   3.0|      5.0|\n",
      "|  75384|     28|   4.0|      5.0|\n",
      "| 452001|     28|   5.0|      5.0|\n",
      "| 282447|     28|   4.0|      5.0|\n",
      "|1646639|     28|   4.0|      5.0|\n",
      "| 714802|     28|   5.0|      5.0|\n",
      "| 591184|     28|   4.0|      5.0|\n",
      "|2554750|     28|   5.0|      5.0|\n",
      "|1290593|     28|   4.0|      5.0|\n",
      "| 633303|     28|   5.0|      5.0|\n",
      "|1249490|     28|   5.0|      5.0|\n",
      "|1563429|     28|   3.0|      5.0|\n",
      "|1704223|     28|   2.0|      5.0|\n",
      "|1787038|     28|   3.0|      5.0|\n",
      "| 875719|     28|   5.0|      5.0|\n",
      "|2375058|     28|   4.0|      5.0|\n",
      "|2252217|     28|   4.0|      5.0|\n",
      "|2179596|     28|   5.0|      5.0|\n",
      "|1745577|     28|   5.0|      5.0|\n",
      "| 830282|     28|   5.0|      5.0|\n",
      "| 393730|     28|   3.0|      5.0|\n",
      "|2229986|     28|   3.0|      5.0|\n",
      "|1518104|     28|   4.0|      5.0|\n",
      "|2057611|     28|   5.0|      5.0|\n",
      "+-------+-------+------+---------+\n",
      "only showing top 25 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final1 = users_movie.join(movies3, on=['userID' ], how='inner')\n",
    "final1.show(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " the predicted and actual are close values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tries for few more examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average over all the users of whose movies similar to the movie 2913 \n",
      "+-------+-------+------+---------+\n",
      "| userID|movieID|rating|predicted|\n",
      "+-------+-------+------+---------+\n",
      "|1063188|   2913|   5.0|      5.0|\n",
      "|1832810|   2913|   5.0|      5.0|\n",
      "| 430738|   2913|   5.0|      5.0|\n",
      "|1419126|   2913|   4.0|      5.0|\n",
      "|1929128|   2913|   4.0|      5.0|\n",
      "|1185461|   2913|   3.0|      5.0|\n",
      "|2518772|   2913|   5.0|      5.0|\n",
      "|2309341|   2913|   4.0|      5.0|\n",
      "| 132731|   2913|   4.0|      5.0|\n",
      "| 155620|   2913|   5.0|      5.0|\n",
      "+-------+-------+------+---------+\n",
      "only showing top 10 rows\n",
      "\n",
      "Average over all the users of whose movies similar to the movie 398 \n",
      "+-------+-------+------+---------+\n",
      "| userID|movieID|rating|predicted|\n",
      "+-------+-------+------+---------+\n",
      "| 858298|   2640|   4.0|      5.0|\n",
      "| 923103|   2640|   3.0|      5.0|\n",
      "|2197203|   2640|   4.0|      5.0|\n",
      "| 941011|   2640|   3.0|      5.0|\n",
      "|  50259|   2640|   4.0|      5.0|\n",
      "|1637299|   2640|   5.0|      5.0|\n",
      "| 552356|   2640|   4.0|      5.0|\n",
      "|2315130|   2640|   5.0|      5.0|\n",
      "|2614568|   2640|   4.0|      5.0|\n",
      "|2508234|   2640|   4.0|     4.75|\n",
      "+-------+-------+------+---------+\n",
      "only showing top 10 rows\n",
      "\n",
      "Average over all the users of whose movies similar to the movie 2640 \n",
      "+-------+-------+------+----------+\n",
      "|movieID| userID|rating|prediction|\n",
      "+-------+-------+------+----------+\n",
      "|      8|1089184|   3.0|       3.0|\n",
      "|   7544|1089184|   1.0|       3.2|\n",
      "|   1884|1089184|   2.0|       3.4|\n",
      "|  10734|1089184|   1.0|       4.1|\n",
      "+-------+-------+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# lets pick an user 199435\n",
    "#users_movie=test_data.filter(\"movieID  == 2913\")\n",
    "#users_movie=test_data.filter(\"movieID  == 398\")\n",
    "users_movie=test_data.filter(\"movieID  == 2640\")\n",
    "\n",
    "#print(\"users of movieid 28 in train set\")\n",
    "#users_movie.show(5)\n",
    "#lets collect them in a list\n",
    "list3 = users_movie.select('userID')\n",
    "array3 = [int(row.userID) for row in list3.collect()]\n",
    "\n",
    "\n",
    "#now lets get all the movies in the train set, that are watched by the same users who watched movie 28\n",
    "count=train_data[train_data['userID'].isin(array3)].count()\n",
    "#print(\"The number of movies in the train set, that are been watched by the same users who watched movie 28:\", count)\n",
    "movies=train_data[train_data['userID'].isin(array3)]\n",
    "#movies.show(5)\n",
    "\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "#lets take only those users who has watched more than 200 movies as the main user movies are 260\n",
    "x=movies.groupBy(\"movieID\").agg(F.count('userID').alias(\"count1\"))\n",
    "y=x.orderBy(x.count1.desc()).limit(4)\n",
    "#y.show()\n",
    "\n",
    "#storing in an array\n",
    "list2 = y.select('movieID')\n",
    "array2 = [int(row.movieID) for row in list2.collect()]\n",
    "\n",
    "from pyspark.sql import functions as F\n",
    "movies2=movies[movies['movieID'].isin(array2)]\n",
    "movies3=movies2.groupBy(\"userID\").agg(F.mean('rating').alias('predicted'))\n",
    "movies3=movies3.orderBy(movies3.predicted.desc())\n",
    "#movies3.show(30)\n",
    "\n",
    "final2 = users_movie.join(movies3, on=['userID' ], how='inner')\n",
    "\n",
    "print(\"Average over all the users of whose movies similar to the movie 2913 \")\n",
    "final1.show(10)\n",
    "print(\"Average over all the users of whose movies similar to the movie 398 \")\n",
    "final2.show(10)\n",
    "print(\"Average over all the users of whose movies similar to the movie 2640 \")\n",
    "final3.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# c) Best approach to implement the collaborative filtering "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several methods of finding similar users such as JACCARD, COSINE, NORMALISATION, and the one we will be using here is going to be based on the Correlation Function. \n",
    "\n",
    "It is used to measure the strength of a linear association between two variables. \n",
    "It is used to measure the strength of a linear association between two variables. The formula for finding this coefficient between sets X and Y with N values can be seen in the image below. \n",
    "\n",
    "Why are we using Pearson Correlation?\n",
    "Pearson correlation is invariant to scaling, i.e. multiplying all elements by a nonzero constant or adding any constant to all elements. For example, if you have two vectors X and Y,then, pearson(X, Y) == pearson(X, 2 * Y + 3). This is a pretty important property in recommendation systems because for example two users might rate two series of items totally different in terms of absolute rates, but they would be similar users (i.e. with similar ideas) with similar rates in various scales .\n",
    "The values given by the formula vary from r = -1 to r = 1, where 1 forms a direct correlation between the two entities (it means a perfect positive correlation) and -1 forms a perfect negative correlation. \n",
    "In our case, a 1 means that the two users have similar tastes while a -1 means the opposite.\n",
    "\n",
    "\n",
    "\n",
    "Jaccard distance is not a suitable?\n",
    "\n",
    "Jaccard distance is not a suitable measure for the kind of data we are considering, because We could ignore values in the matrix and focus only on the sets of items rated meaning it takes the union and intersections of user A and B. If our problem statement was only about watching movies and not about ratings, then Jaccard distance would be a good choice to use. But, in this project, we are dealing with detailed ratings (1 being lowest and 5 being highest), the Jaccard distance loses important information. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# d) Applying Correlation Coefficient and rerunning the code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The process for creating a User Based recommendation system is as follows:\n",
    "1.\tFirst select a user with the movies the user has watched\n",
    "\n",
    "2.\tBased on his rating to movies, find the top X neighbours/ similar users\n",
    "\n",
    "3.\tGet the watched movie record of the user for each neighbour.\n",
    "\n",
    "4.\tCalculate a similarity score using the formula\n",
    "\n",
    "5.\tRecommend the items with the highest score\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User-based Collaborative Filtering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_data\n",
    "#test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### lets pick an user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movies of userid 199435  in train set\n",
      "+-------+------+------+\n",
      "|movieID|userID|rating|\n",
      "+-------+------+------+\n",
      "|   8596|199435|   5.0|\n",
      "|    443|199435|   3.0|\n",
      "|   7145|199435|   3.0|\n",
      "|  14144|199435|   3.0|\n",
      "|  14712|199435|   3.0|\n",
      "|   4852|199435|   2.0|\n",
      "|  10082|199435|   2.0|\n",
      "|  12778|199435|   2.0|\n",
      "+-------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# lets pick an user 1395430  from test dataset\n",
    "movies_user=test_data.filter(\"userID  == 199435\")\n",
    "print(\"movies of userid 199435  in train set\")\n",
    "\n",
    "#there are many movies, let take only top ones that has rating 5. \n",
    "x=movies_user.orderBy(movies_user.rating.desc())\n",
    "userInput=x.limit(10)\n",
    "userInput.show()\n",
    "#collect the movieids in an array\n",
    "l = userInput.select('movieID')\n",
    "a = [int(row.movieID) for row in l.collect()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    " \n",
    " \n",
    " ####  The users who has seen the same movies from train dataset\n",
    " \n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+------+\n",
      "|movieID| userID|rating|\n",
      "+-------+-------+------+\n",
      "|    443| 364518|   3.0|\n",
      "|    443| 716091|   4.0|\n",
      "|    443|1601783|   4.0|\n",
      "|    443| 306466|   3.0|\n",
      "|    443| 160977|   5.0|\n",
      "+-------+-------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "92691"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similaruser = train_data[train_data['movieID'].isin(a)]\n",
    "similaruser.show(5)\n",
    "similaruser.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets take only 100\n",
    "#similarusers=similaruser.limit(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We dont want to run for whole data so lets take only 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarusers=similaruser.select('userID').distinct()\n",
    "similar=similarusers.limit(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#collecting in a list\n",
    "l1 = similar.select('userID')\n",
    "similaruser_ids = [int(row.userID) for row in l1.collect()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculating the Pearson Correlation between input user and subset group, and store it in a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pearsonCorrelationDict={}\n",
    "import  numpy as np\n",
    "for i in similaruser_ids:\n",
    "    #get each userid from the similarusers file and sort it by movieid\n",
    "    group =  similaruser[similaruser['userID'].isin(i)]\n",
    "    group=group.orderBy(group.movieID.desc())\n",
    "    #group.show()\n",
    "    #store them in an array \n",
    "    l2 = group.select('movieID')\n",
    "    a2 = [int(row.movieID) for row in l2.collect()]\n",
    "    #get each userInput  file and sort it by movieid\n",
    "    userInput1=userInput.orderBy(userInput.movieID.desc())\n",
    "    #userInput1.show()\n",
    "    #get the number of rows of the groupfile\n",
    "    nRatings = group.count()\n",
    "    #Get the rating scores for the movies that they both have in common\n",
    "    temp_df = userInput1[userInput1['movieID'].isin(a2)] \n",
    "    l3 = temp_df.select('rating')\n",
    "    #store in a list\n",
    "    rating_tempdf = [int(row.rating) for row in l3.collect()]\n",
    "    #print(\"rating_tempdf\",rating_tempdf)\n",
    "    #Get the rating scores for the group data\n",
    "    l4 = group.select('rating')\n",
    "    #store in a list\n",
    "    rating_group = [int(row.rating) for row in l4.collect()]\n",
    "    #print(\"rating_group\",rating_group)\n",
    "    \n",
    "    #Now let's calculate the pearson correlation between two users, so called, x and y\n",
    "    Sxx = sum([i**2 for i in rating_tempdf]) - pow(sum(rating_tempdf),2)/float(nRatings)\n",
    "    Syy = sum([i**2 for i in rating_group]) - pow(sum(rating_group),2)/float(nRatings)\n",
    "    Sxy = sum( i*j for i, j in zip(rating_tempdf, rating_group)) - sum(rating_tempdf)*sum(rating_group)/float(nRatings)\n",
    "    \n",
    "    if Sxx != 0 and Syy != 0:\n",
    "        pearsonCorrelationDict[i] = Sxy/(np.sqrt(Sxx*Syy))\n",
    "    else:\n",
    "        pearsonCorrelationDict[i] = 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([(128389, -0.22075539284417398), (2228253, 0), (2311863, 0.0), (2629660, 0.6123724356957946), (1742759, 0.4482758620689666), (279120, 0), (1553158, 0), (2088272, 1.0), (1896167, -1.0), (2358799, 0.7559289460184533), (15846, 0.49999999999999667), (953170, 0.41403933560541256), (1552084, 0.2886751345948129), (455334, 0.9449111825230695), (1629521, 0.47368421052631576), (2531111, -0.5000000000000008), (1497891, 0.866025403784439), (637596, 0.866025403784439), (973051, 0), (2250628, 0), (1628484, 0.0), (446160, 0.2075143391598224), (675056, -0.9449111825230686), (1909175, 1.0), (1434507, 0), (1704384, 0.49999999999999933), (1214262, 1.0), (2613898, -0.866025403784439), (216558, 1.000000000000004), (2305305, 0.7559289460184573), (761430, 0), (836945, 0.866025403784439), (1213587, 0), (1610263, 0.7385489458759964), (434567, 0.4999999999999982), (377808, 0.9449111825230686), (1849621, 0.981980506061966), (2339191, 0.9449111825230686), (2482819, 1.0), (1919244, 1.0), (1607539, 0.18898223650461402), (1100552, -0.7559289460184573), (964825, -0.5000000000000007), (918562, -0.9999999999999987), (837636, -0.49999999999999933), (1998719, 0.3746343246326776), (2114400, -0.9449111825230636), (599480, 0.13245323570650439), (1684416, 0.899228803025897), (1452396, 0.48420012470625223), (168902, 1.000000000000004), (1044232, 0), (191869, 0.16666666666666666), (1990345, 0), (1973956, 0), (861862, 0.13245323570650439), (2320450, 0), (713980, 0), (1902140, -0.6622661785325219), (110938, 0.4969039949999533), (561364, 1.0), (2120968, 1.0), (1439577, 0.6488856845230502), (328283, 0), (1983441, 0), (839232, 0.9449111825230686), (2056554, 0.47140452079103173), (460258, 0), (2354764, 0.15309310892394898), (2232581, 0.18898223650461435), (1221563, 0.6882472016116852), (755549, -0.14285714285714243), (1300124, 0.3244428422615251), (1559165, 0.6123724356957964), (732375, 0.6546536707079773), (1042614, -0.22941573387056174), (1408341, 0.3726779962499645), (1888899, -0.7559289460184548), (2134425, 0.9271726499455306), (2271702, 0.41522739926870117), (2165353, 0.3825460278380029), (834611, 0), (525597, 0.6666666666666676), (1069088, 0.3333333333333333), (2153439, 0), (423167, 0.20412414523193154), (1675105, -0.13245323570650439), (841091, 0.7492686492653552), (1005202, 0.6488856845230502), (1704248, 0.6546536707079773), (2262372, -0.32732683535398865), (214848, 0), (381625, 0), (649264, 0.5000000000000008), (2453706, 0.49999999999999933), (2125852, 0.13245323570650439), (2520933, 1.0), (2331938, 0.4082482904638631), (2472440, 0.8660254037844387), (411705, 0.0)])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pearsonCorrelationDict.items()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting dictionary to dataframe and shorting in descending order\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF = pandas.DataFrame.from_dict(pearsonCorrelationDict, orient='index')\n",
    "DF.columns = ['similarityIndex']\n",
    "DF['userId'] = DF.index\n",
    "DF.index = range(len(DF))\n",
    "ddf = spark.createDataFrame(DF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------+\n",
      "|     similarityIndex| userId|\n",
      "+--------------------+-------+\n",
      "|-0.22075539284417398| 128389|\n",
      "|                 0.0|2228253|\n",
      "|                 0.0|2311863|\n",
      "|  0.6123724356957946|2629660|\n",
      "|  0.4482758620689666|1742759|\n",
      "|                 0.0| 279120|\n",
      "|                 0.0|1553158|\n",
      "|                 1.0|2088272|\n",
      "|                -1.0|1896167|\n",
      "|  0.7559289460184533|2358799|\n",
      "| 0.49999999999999667|  15846|\n",
      "| 0.41403933560541256| 953170|\n",
      "|  0.2886751345948129|1552084|\n",
      "|  0.9449111825230695| 455334|\n",
      "| 0.47368421052631576|1629521|\n",
      "| -0.5000000000000008|2531111|\n",
      "|   0.866025403784439|1497891|\n",
      "|   0.866025403784439| 637596|\n",
      "|                 0.0| 973051|\n",
      "|                 0.0|2250628|\n",
      "+--------------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ddf.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The top x similar users to input user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "topUsers=ddf.orderBy(ddf.similarityIndex.desc())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-------+\n",
      "|   similarityIndex| userId|\n",
      "+------------------+-------+\n",
      "| 1.000000000000004| 168902|\n",
      "| 1.000000000000004| 216558|\n",
      "|               1.0|2482819|\n",
      "|               1.0|1919244|\n",
      "|               1.0| 561364|\n",
      "|               1.0|2520933|\n",
      "|               1.0|2120968|\n",
      "|               1.0|1909175|\n",
      "|               1.0|2088272|\n",
      "|               1.0|1214262|\n",
      "| 0.981980506061966|1849621|\n",
      "|0.9449111825230695| 455334|\n",
      "|0.9449111825230686|2339191|\n",
      "|0.9449111825230686| 377808|\n",
      "|0.9449111825230686| 839232|\n",
      "|0.9271726499455306|2134425|\n",
      "| 0.899228803025897|1684416|\n",
      "| 0.866025403784439| 836945|\n",
      "| 0.866025403784439| 637596|\n",
      "| 0.866025403784439|1497891|\n",
      "+------------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "topUsers.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now, recommending movies to the input user.\n",
    "\n",
    "#### Taking the weighted average of the ratings of the movies using the Pearson Correlation as the weight.\n",
    "But to do this, we first need to get the movies watched by the users in our __DF__ from the ratings dataframe and then store their correlation in a new column called _similarityIndex\". This is achieved below by merging of these two tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = topUsers.join(similaruser, on=['userId' ], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+-------+------+\n",
      "| userId|    similarityIndex|movieID|rating|\n",
      "+-------+-------------------+-------+------+\n",
      "|1742759| 0.4482758620689666|    443|   2.0|\n",
      "| 460258|                0.0|    443|   4.0|\n",
      "|1221563| 0.6882472016116852|    443|   4.0|\n",
      "|2153439|                0.0|    443|   5.0|\n",
      "| 861862|0.13245323570650439|    443|   4.0|\n",
      "| 839232| 0.9449111825230686|    443|   4.0|\n",
      "| 973051|                0.0|    443|   5.0|\n",
      "|1434507|                0.0|    443|   5.0|\n",
      "|2271702|0.41522739926870117|    443|   5.0|\n",
      "| 637596|  0.866025403784439|    443|   3.0|\n",
      "| 110938| 0.4969039949999533|    443|   4.0|\n",
      "|1005202| 0.6488856845230502|    443|   4.0|\n",
      "|1559165| 0.6123724356957964|    443|   4.0|\n",
      "|1896167|               -1.0|    443|   4.0|\n",
      "| 328283|                0.0|    443|   5.0|\n",
      "|1684416|  0.899228803025897|    443|   2.0|\n",
      "| 381625|                0.0|    443|   4.0|\n",
      "|2520933|                1.0|    443|   3.0|\n",
      "|1069088| 0.3333333333333333|    443|   3.0|\n",
      "| 761430|                0.0|    443|   5.0|\n",
      "+-------+-------------------+-------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets calculate the similarity index by multiply the movie rating by its weight, \n",
    "then sum up the new ratings and divide it by the sum of the weights.\n",
    "\n",
    "It shows the idea of all similar users to candidate movies for the input user:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+-------+------+------------------+\n",
      "| userId|    similarityIndex|movieID|rating|    weightedRating|\n",
      "+-------+-------------------+-------+------+------------------+\n",
      "|1742759| 0.4482758620689666|    443|   2.0|0.8965517241379332|\n",
      "| 460258|                0.0|    443|   4.0|               0.0|\n",
      "|1221563| 0.6882472016116852|    443|   4.0|2.7529888064467407|\n",
      "|2153439|                0.0|    443|   5.0|               0.0|\n",
      "| 861862|0.13245323570650439|    443|   4.0|0.5298129428260175|\n",
      "| 839232| 0.9449111825230686|    443|   4.0|3.7796447300922744|\n",
      "| 973051|                0.0|    443|   5.0|               0.0|\n",
      "|1434507|                0.0|    443|   5.0|               0.0|\n",
      "|2271702|0.41522739926870117|    443|   5.0| 2.076136996343506|\n",
      "| 637596|  0.866025403784439|    443|   3.0| 2.598076211353317|\n",
      "| 110938| 0.4969039949999533|    443|   4.0|1.9876159799998132|\n",
      "|1005202| 0.6488856845230502|    443|   4.0|2.5955427380922007|\n",
      "|1559165| 0.6123724356957964|    443|   4.0|2.4494897427831854|\n",
      "|1896167|               -1.0|    443|   4.0|              -4.0|\n",
      "| 328283|                0.0|    443|   5.0|               0.0|\n",
      "|1684416|  0.899228803025897|    443|   2.0| 1.798457606051794|\n",
      "| 381625|                0.0|    443|   4.0|               0.0|\n",
      "|2520933|                1.0|    443|   3.0|               3.0|\n",
      "|1069088| 0.3333333333333333|    443|   3.0|               1.0|\n",
      "| 761430|                0.0|    443|   5.0|               0.0|\n",
      "+-------+-------------------+-------+------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#multiply\n",
    "new_df1=new_df.withColumn('weightedRating', (col('similarityIndex') * col('rating')))\n",
    "new_df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "temp=new_df1.groupBy('movieID').agg(F.sum(new_df1.similarityIndex).alias(\"SI_sum\"),F.sum(new_df1.weightedRating).alias(\"WR_sum\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+\n",
      "|movieID|            SI_sum|            WR_sum|\n",
      "+-------+------------------+------------------+\n",
      "|  10082| 6.762463820697189|18.512183134051664|\n",
      "|   4852| 6.202397253085562| 17.49336617354312|\n",
      "|   8596|28.005071129964108|139.25153230950056|\n",
      "|  14144| 5.424940182070157| 19.35571539109325|\n",
      "|    443| 7.545557310351263| 26.00181992951127|\n",
      "|  12778|15.420285028238624| 49.15830219942137|\n",
      "|   7145| 8.981991714248839| 29.32700876370245|\n",
      "|  14712|20.449127741359334|  59.8559381486637|\n",
      "+-------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "temp.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### weighted average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendation=temp.withColumn('weighted_average', (col('WR_sum') / col('SI_sum')))\n",
    "recommendation=recommendation.select(\"movieID\",\"weighted_average\")\n",
    "recommendation=recommendation.orderBy(recommendation.weighted_average.desc()).limit(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### These are the movies that  are the predicted rating of 1395430"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|movieID|  weighted_average|\n",
      "+-------+------------------+\n",
      "|   8596| 4.972368456529574|\n",
      "|  14144|3.5679131458564965|\n",
      "|    443| 3.445977395710858|\n",
      "|   7145| 3.265089714698658|\n",
      "|  12778|3.1878984149384726|\n",
      "|  14712| 2.927065589580245|\n",
      "|   4852|2.8204201472004296|\n",
      "|  10082| 2.737490894575036|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "recommendation.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = recommendation.select('movieID')\n",
    "n = [int(row.movieID) for row in m.collect()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual=movies_user[movies_user['movieID'].isin(n)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+------+\n",
      "|movieID|userID|rating|\n",
      "+-------+------+------+\n",
      "|    443|199435|   3.0|\n",
      "|   4852|199435|   2.0|\n",
      "|   7145|199435|   3.0|\n",
      "|   8596|199435|   5.0|\n",
      "|  10082|199435|   2.0|\n",
      "|  12778|199435|   2.0|\n",
      "|  14144|199435|   3.0|\n",
      "|  14712|199435|   3.0|\n",
      "+-------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "actual.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "final1 = userInput.join(recommendation, on=['movieID' ], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+------+------------------+\n",
      "|movieID|userID|rating|  weighted_average|\n",
      "+-------+------+------+------------------+\n",
      "|   8596|199435|   5.0| 4.972368456529574|\n",
      "|    443|199435|   3.0|3.4459773957108584|\n",
      "|   7145|199435|   3.0| 3.265089714698658|\n",
      "|  14144|199435|   3.0| 3.567913145856496|\n",
      "|  14712|199435|   3.0| 2.927065589580245|\n",
      "|   4852|199435|   2.0|2.8204201472004296|\n",
      "|  10082|199435|   2.0|2.7374908945750356|\n",
      "|  12778|199435|   2.0|3.1878984149384726|\n",
      "+-------+------+------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if we want to see the name of the movie, join it with movie_titles dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "final2= final1.join(movie_name, on=['movieID'], how='inner')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
