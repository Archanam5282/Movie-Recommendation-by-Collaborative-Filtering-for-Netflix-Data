{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1: Collaborative Filtering Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing the ALS approach for the netflix data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loading thr data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.sql import SparkSession ,Row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change to the location of data files\n",
    "dbfs_dir = 's3://archanamaroldsde.bucket/'\n",
    "test = dbfs_dir + '/TestingRatings.txt'\n",
    "train = dbfs_dir + '/TrainingRatings.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import regexp_extract\n",
    "from pyspark.sql.types import *\n",
    "tests=sqlContext.read.text(test)\n",
    "trains=sqlContext.read.text(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as f\n",
    "test_data = tests.select(f.split(tests.value,\",\")).rdd.flatMap(lambda x: x).toDF(schema=[\"movieID\",\"userID\", \"rating\"])\n",
    "train_data = trains.select(f.split(trains.value,\",\")).rdd.flatMap(lambda x: x).toDF(schema=[\"movieID\",\"userID\", \"rating\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting types\n",
    "test_data = test_data.withColumn(\"movieID\",test_data[\"movieID\"].cast(IntegerType()))\n",
    "test_data = test_data.withColumn(\"userID\",test_data[\"userID\"].cast(IntegerType()))\n",
    "test_data = test_data.withColumn(\"rating\",test_data[\"rating\"].cast(FloatType()))\n",
    "\n",
    "train_data = train_data.withColumn(\"movieID\",train_data[\"movieID\"].cast(IntegerType()))\n",
    "train_data = train_data.withColumn(\"userID\",train_data[\"userID\"].cast(IntegerType()))\n",
    "train_data = train_data.withColumn(\"rating\",train_data[\"rating\"].cast(FloatType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.cache()\n",
    "train_data.cache()\n",
    "assert test_data.is_cached\n",
    "assert train_data.is_cached"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 3255352 rows in the train datasets\n",
      "There are 100478 rows in the test datasets\n"
     ]
    }
   ],
   "source": [
    "train_data_count = train_data.count()\n",
    "test_data_count = test_data.count()\n",
    "print('There are %s rows in the train datasets' % (train_data_count))\n",
    "print('There are %s rows in the test datasets' % (test_data_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### split the test data into validation and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1800009193"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "( test_data1, test_data2) =(test_data.randomSplit([ 0.5, 0.5], seed = 1800009193))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ALS model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "als = ALS()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For rank 4 the RMSE is 0.870632365922693\n",
      "For rank 8 the RMSE is 0.8595219560970704\n",
      "For rank 12 the RMSE is 0.8662888532087158\n",
      "The best model was trained with rank 8\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.recommendation import ALS\n",
    "\n",
    "als = ALS()\n",
    "\n",
    "als.setMaxIter(5)\\\n",
    "   .setSeed(seed)\\\n",
    "   .setRegParam(0.1)\\\n",
    "   .setUserCol(\"userID\").setItemCol(\"movieID\").setRatingCol(\"rating\")\n",
    "\n",
    "\n",
    "reg_eval = RegressionEvaluator(predictionCol=\"prediction\", labelCol=\"rating\", metricName=\"rmse\")\n",
    "\n",
    "tolerance = 0.03\n",
    "ranks = [4, 8, 12]\n",
    "errors = [0, 0, 0]\n",
    "models = [0, 0, 0]\n",
    "err = 0\n",
    "min_error = float('inf')\n",
    "best_rank = -1\n",
    "for rank in ranks:\n",
    "  #Set\n",
    "  als.setRank(rank)\n",
    "  #\n",
    "  model = als.fit(train_data)\n",
    "  # \n",
    "  predict_df = model.transform(test_data1)\n",
    "\n",
    "  # \n",
    "  predicted_ratings_df = predict_df.filter(predict_df.prediction != float('nan'))\n",
    "  error = reg_eval.evaluate(predicted_ratings_df)\n",
    "  errors[err] = error\n",
    "  models[err] = model\n",
    "  print('For rank %s the RMSE is %s' % (rank, error))\n",
    "  if error < min_error:\n",
    "    min_error = error\n",
    "    best_rank = err\n",
    "  err += 1\n",
    "als.setRank(ranks[best_rank])\n",
    "print('The best model was trained with rank %s' % ranks[best_rank])\n",
    "my_model = models[best_rank]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction and RMSE evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model had a RMSE on the test set of 0.8637122515990271\n"
     ]
    }
   ],
   "source": [
    "predict_df = my_model.transform(test_data2)\n",
    "\n",
    "predicted_test_df = predict_df.filter(predict_df.prediction != float('nan'))\n",
    "\n",
    "test_RMSE = reg_eval.evaluate(predicted_test_df)\n",
    "print('The model had a RMSE on the test set of {0}'.format(test_RMSE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
